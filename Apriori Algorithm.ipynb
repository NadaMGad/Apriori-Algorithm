{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4171de94-9a57-416c-a362-efc6715887d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UsingApriori Algorithm\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox, Scrollbar\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "def preprocess_data(df):\n",
    "    df = df[['TransactionNo', 'Items']].copy() #Create a copy of the selecting attributes(TransactionNo,Items)\n",
    "    df.drop_duplicates(inplace=True) #remove duplicate rows\n",
    "    return df\n",
    " #open file from browser\n",
    "def open_file():\n",
    "    global df\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"CSV files\", \"*.csv\"), (\"Excel files\", \"*.xlsx\")])\n",
    "    if file_path:\n",
    "        try:\n",
    "            if file_path.endswith('.csv'):\n",
    "                df = pd.read_csv(file_path)\n",
    "            elif file_path.endswith('.xlsx'):\n",
    "                df = pd.read_excel(file_path)\n",
    "                \n",
    "            df = preprocess_data(df)\n",
    "            update_info_label(f\"File Loaded: {file_path}\")\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"Error loading file: {e}\")\n",
    "\n",
    "def update_info_label(message):\n",
    "    info_text.config(state=tk.NORMAL)\n",
    "    info_text.delete(\"1.0\", tk.END)\n",
    "    info_text.insert(tk.END, message)\n",
    "    info_text.config(state=tk.DISABLED)\n",
    "\n",
    "def generate_candidate_itemsets(transactions, k):\n",
    "    candidate_itemsets = []\n",
    "    for transaction in transactions:\n",
    "        candidate_itemsets.extend(combinations(sorted(transaction), k))\n",
    "    return list(set(candidate_itemsets)) #set to remove duplicate items\n",
    "\n",
    "def count_support(transactions, candidate_itemsets):\n",
    "    support_counts = {}\n",
    "    for itemset in candidate_itemsets:\n",
    "        for transaction in transactions:\n",
    "            if set(itemset).issubset(transaction):\n",
    "                support_counts[itemset] = support_counts.get(itemset, 0) + 1\n",
    "    return support_counts\n",
    "\n",
    "def generate_frequent_itemsets(support_counts, min_supportcount):\n",
    "    frequent_itemsets = {itemset: support for itemset, support in support_counts.items() if support >= min_supportcount}\n",
    "    return frequent_itemsets\n",
    "\n",
    "def generate_association_rules(frequent_itemsets, min_confidence):\n",
    "    association_rules = set()  # Use a set to avoid duplicates\n",
    "    max_length = max(len(itemset) for itemset in frequent_itemsets.keys())\n",
    "    \n",
    "    for itemset in frequent_itemsets.keys():\n",
    "        if len(itemset) == max_length:\n",
    "            if len(itemset) > 1:\n",
    "                for i in range(1, len(itemset)):\n",
    "                    for antecedent in combinations(sorted(itemset), i):\n",
    "                        consequent = tuple(sorted(set(itemset) - set(antecedent)))\n",
    "                        confidence = frequent_itemsets[itemset] / frequent_itemsets[antecedent]\n",
    "                        if confidence >= min_confidence:\n",
    "                            rule = (antecedent, consequent, confidence)\n",
    "                            # Check for duplicates before adding\n",
    "                            is_duplicate = False\n",
    "                            for existing_rule in association_rules:\n",
    "                                if set(rule[0]) == set(existing_rule[0]) and set(rule[1]) == set(existing_rule[1]):\n",
    "                                    is_duplicate = True\n",
    "                                    break\n",
    "                            if not is_duplicate:\n",
    "                                association_rules.add(rule)\n",
    "    return association_rules\n",
    "\n",
    "\n",
    "def process_data():\n",
    "    global df\n",
    "    try:\n",
    "        min_support_count = int(min_support_entry.get())\n",
    "        min_confidence = float(min_confidence_entry.get()) / 100\n",
    "        percentage = float(percentage_entry.get()) / 100\n",
    "        if df.empty:\n",
    "            messagebox.showerror(\"Error\", \"No data loaded. Please load a file.\")\n",
    "            return\n",
    "        num_records_to_read = int(len(df) * percentage)\n",
    "        df_subset = df.head(num_records_to_read)\n",
    "        \n",
    "        transactions = df_subset.groupby('TransactionNo')['Items'].apply(list).tolist()\n",
    "        \n",
    "        frequent_itemsets = {}\n",
    "        k = 1  \n",
    "        while True:  # Loop indefinitely until break\n",
    "            candidate_itemsets = generate_candidate_itemsets(transactions, k)\n",
    "            support_counts = count_support(transactions, candidate_itemsets)\n",
    "            new_frequent_itemsets = generate_frequent_itemsets(support_counts, min_support_count)\n",
    "            \n",
    "            # Check if new frequent itemsets are generated\n",
    "            if not new_frequent_itemsets:\n",
    "                break \n",
    "            \n",
    "            # Update frequent_itemsets with new frequent itemsets\n",
    "            frequent_itemsets.update(new_frequent_itemsets)\n",
    "            \n",
    "            # Increment k for the next iteration\n",
    "            k += 1\n",
    "        \n",
    "        association_rules = generate_association_rules(frequent_itemsets, min_confidence)\n",
    "        \n",
    "        Apriori_Algorithm_text=\"Using Apriori Algorithm :\\n\" \n",
    "        frequent_item_sets_text = \"Frequent Item Sets:\\n\"\n",
    "        for itemset, support in frequent_itemsets.items():\n",
    "            frequent_item_sets_text += str(itemset) + \" : \" + str(support) + \"\\n\"\n",
    "\n",
    "        strong_association_rules_text = \"\\nStrong Association Rules:\\n\"\n",
    "        for rule in association_rules:\n",
    "            strong_association_rules_text += f\"{rule[0]} -> {rule[1]} : {rule[2]}\\n\"\n",
    "\n",
    "        update_info_label(frequent_item_sets_text + strong_association_rules_text)\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", f\"Error processing data: {e}\")\n",
    "\n",
    "panel = tk.Tk()\n",
    "panel.title(\"Association Rule Mining Tool\")\n",
    "panel.geometry(\"800x600\")\n",
    "panel.configure(bg=\"lightblue\")\n",
    "\n",
    "title_label = tk.Label(panel, text=\"Association Rule Mining Tool\", font=(\"Arial\", 20), bg=\"lightblue\")\n",
    "title_label.pack(pady=20)\n",
    "\n",
    "open_button = tk.Button(panel, text=\"Open File\", command=open_file, font=(\"Arial\", 12))\n",
    "open_button.pack(pady=10)\n",
    "\n",
    "percentage_label = tk.Label(panel, text=\"Percentage of Data to Read (%):\", font=(\"Arial\", 12), bg=\"lightblue\")\n",
    "percentage_label.pack()\n",
    "percentage_entry = tk.Entry(panel, font=(\"Arial\", 12))\n",
    "percentage_entry.pack()\n",
    "\n",
    "min_support_label = tk.Label(panel, text=\"Minimum Support Count:\", font=(\"Arial\", 12), bg=\"lightblue\")\n",
    "min_support_label.pack()\n",
    "min_support_entry = tk.Entry(panel, font=(\"Arial\", 12))\n",
    "min_support_entry.pack()\n",
    "\n",
    "min_confidence_label = tk.Label(panel, text=\"Minimum Confidence (%):\", font=(\"Arial\", 12), bg=\"lightblue\")\n",
    "min_confidence_label.pack()\n",
    "min_confidence_entry = tk.Entry(panel, font=(\"Arial\", 12))\n",
    "min_confidence_entry.pack()\n",
    "\n",
    "process_button = tk.Button(panel, text=\"Process Data\", command=process_data, font=(\"Arial\", 12))\n",
    "process_button.pack(pady=20)\n",
    "\n",
    "output_frame = tk.Frame(panel)\n",
    "output_frame.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "info_text = tk.Text(output_frame, wrap=\"none\")\n",
    "info_text.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "\n",
    "scrollbar = tk.Scrollbar(output_frame, command=info_text.yview)\n",
    "scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "\n",
    "info_text.config(yscrollcommand=scrollbar.set)\n",
    "\n",
    "panel.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da155f2b-59ea-4001-84af-9ca5aba02ce9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
